{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting it all together with Neo4J\n",
    "\n",
    "In this section, we put everything we learned in previous sections into practice by creating an LLM agent that will answer user questions about a hospital. To do that we use two datasources: a Neo4J vector indices that contain documents on user reviews of different hospitals and a Neo4J graph database containing information about those hospitals, visits, doctors, payments, etc. Our RAG pipeline will correctly re-direct the user query to each datasource and will answer the question in the end. Let's begin!\n",
    "\n",
    "| ![arag](resources/final.png) | \n",
    "|:--:| \n",
    "| *RAG based hospital information system* |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dotenv extension is already loaded. To reload it, use:\n",
      "  %reload_ext dotenv\n"
     ]
    }
   ],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv secrets/secrets.env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain import hub\n",
    "from typing import Literal\n",
    "from neo4j import GraphDatabase\n",
    "\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"hospital-system\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use a processed Kaggle dataset by [Harrison Hoffman](https://github.com/hfhoffman1144). The processed dataset contains 6 `.csv` files.\n",
    "\n",
    "- `hospitals.csv`: Contains the names of the hospitals, the state that the hospital is located, and a unique id.\n",
    "- `physicians.csv`: Contains information about physicians including their names, date of birth, graduation year, medical school, and salary.\n",
    "- `payers.csv`: Contains names and unique ids of five different insurance companies that paid bills of patients.\n",
    "- `patients.csv`: Contains information about patients and their sex, date of birth, blood type, identified by a unique id.\n",
    "- `visits.csv`: This file connects all the mentioned files with information about each patient's visits, date of admission, billing amount, room number, admission type, discharge date, test results, visit id, physician id, payer id, hospital id, chief complaint, treatment description, primary diagnosis, and visit status.\n",
    "- `reviews.csv`: Contains user reviews posted by patients in their respective visits treated by a physician in a hospital. \n",
    "\n",
    "\n",
    "Next we use the above CSV files and relationships between them are used to create a Neo4J graph in [Neo4J AuraDB](https://neo4j.com/cloud/platform/aura-graph-database/?utm_source=Google&utm_medium=PaidSearch&utm_campaign=Evergreen&utm_content=APAC-Search-SEMBrand-Evergreen-None-SEM-SEM-NonABM&utm_term=auradb&utm_adgroup=auradb&gad_source=1&gclid=Cj0KCQjw6auyBhDzARIsALIo6v-fHIGNfhxYHr6ZxUpuoE-wSFEfJHw93acnry6XSQ5JTZKMlJ84ojQaAthHEALw_wcB). You can create an account for free and create a DB instance hosted in GCP. You need to download the login information needed for authentication through the neo4j python library and langchain. The login information should contain: \n",
    "\n",
    "- NEO4J_URI\n",
    "- NEO4J_USERNAME\n",
    "- NEO4J_PASSWORD\n",
    "- AURA_INSTANCEID\n",
    "- AURA_INSTANCENAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph we are going to build is as follows. \n",
    "\n",
    "| ![arag](resources/graph.png) | \n",
    "|:--:| \n",
    "| *Neo4J Graph for the hospital information system* |\n",
    "\n",
    "Each circle represents a \"Node\" and each arrow represents a \"Relationship\". \n",
    "\n",
    "For instance, each *Patient* **HAS** a *Visit* **AT** a *Hospital* that **EMPLOYS** a *Physician* who **TREATS** in a *Visit* **COVERED_BY** a *Payer*. A *Patient* who completed a *Visit* **WRITES** a *Review* in the end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we create the aforementioned nodes and relationships between them (i.e., the graph) in AuraDB using the [Cypher query language](https://neo4j.com/product/cypher-graph-query-language/?utm_source=Google&utm_medium=PaidSearch&utm_campaign=Evergreen&utm_content=AMS-Search-SEMBrand-Evergreen-None-SEM-SEM-NonABM&utm_term=cypher%20query%20language&utm_adgroup=cypher-language&gad_source=1&gclid=Cj0KCQjw6auyBhDzARIsALIo6v9vwpW2dCruoed6H21Hsv12uccW6jF9oAgfqPKAgzeN27_8Xnm6ecEaAk9LEALw_wcB), and populate it with the information in CSV files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`````{admonition} See also\n",
    ":class: tip\n",
    "For more information about the Cypher Query Language refer to the [documentation](https://neo4j.com/product/cypher-graph-query-language/?utm_source=Google&utm_medium=PaidSearch&utm_campaign=Evergreen&utm_content=AMS-Search-SEMBrand-Evergreen-None-SEM-SEM-NonABM&utm_term=cypher%20query%20language&utm_adgroup=cypher-language&gad_source=1&gclid=Cj0KCQjw6auyBhDzARIsALIo6v9vwpW2dCruoed6H21Hsv12uccW6jF9oAgfqPKAgzeN27_8Xnm6ecEaAk9LEALw_wcB). Python SDK documentation can be found [here](https://neo4j.com/docs/python-manual/current/).\n",
    "`````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "NODES = [\"Hospital\", \"Payer\", \"Physician\", \"Patient\", \"Visit\", \"Reviews\"]\n",
    "\n",
    "def _set_uniqueness_constraints(tx, node):\n",
    "    query = f\"\"\"CREATE CONSTRAINT IF NOT EXISTS FOR (n:{node})\n",
    "        REQUIRE n.id IS UNIQUE;\"\"\"\n",
    "    _ = tx.run(query, {})\n",
    "    \n",
    "\n",
    "driver = GraphDatabase.driver(\n",
    "    os.getenv('NEO4J_URI'),\n",
    "    auth=(os.getenv('NEO4J_USERNAME'), os.getenv('NEO4J_PASSWORD'))\n",
    ")\n",
    "with driver.session(database=\"neo4j\") as session:\n",
    "    for node in NODES:\n",
    "        session.execute_write(_set_uniqueness_constraints, node)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOSPITALS = \"https://raw.githubusercontent.com/sakunaharinda/ragatouille/main/data/hospitals.csv\"\n",
    "\n",
    "with driver.session(database=\"neo4j\") as session:\n",
    "    query = f\"\"\"\n",
    "    LOAD CSV WITH HEADERS\n",
    "    FROM '{HOSPITALS}' AS hospitals\n",
    "    MERGE (h:Hospital {{id: toInteger(hospitals.hospital_id),\n",
    "                            name: hospitals.hospital_name,\n",
    "                            state_name: hospitals.hospital_state}});\n",
    "    \"\"\"\n",
    "    _ = session.run(query, {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAYERS = \"https://raw.githubusercontent.com/sakunaharinda/ragatouille/main/data/payers.csv\"\n",
    "\n",
    "with driver.session(database=\"neo4j\") as session:\n",
    "    query = f\"\"\"\n",
    "    LOAD CSV WITH HEADERS\n",
    "    FROM '{PAYERS}' AS payers\n",
    "    MERGE (p:Payer {{id: toInteger(payers.payer_id),\n",
    "    name: payers.payer_name}});\n",
    "    \"\"\"\n",
    "    _ = session.run(query, {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "PHYSICIANS = \"https://raw.githubusercontent.com/sakunaharinda/ragatouille/main/data/physicians.csv\"\n",
    "\n",
    "with driver.session(database=\"neo4j\") as session:\n",
    "    query = f\"\"\"\n",
    "    LOAD CSV WITH HEADERS\n",
    "    FROM '{PHYSICIANS}' AS physicians\n",
    "    MERGE (p:Physician {{id: toInteger(physicians.physician_id),\n",
    "                        name: physicians.physician_name,\n",
    "                        dob: physicians.physician_dob,\n",
    "                        grad_year: physicians.physician_grad_year,\n",
    "                        school: physicians.medical_school,\n",
    "                        salary: toFloat(physicians.salary)\n",
    "                        }});\n",
    "    \"\"\"\n",
    "    _ = session.run(query, {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "VISITS = \"https://raw.githubusercontent.com/sakunaharinda/ragatouille/main/data/visits.csv\"\n",
    "\n",
    "with driver.session(database=\"neo4j\") as session:\n",
    "    query = f\"\"\"\n",
    "    LOAD CSV WITH HEADERS FROM '{VISITS}' AS visits\n",
    "    MERGE (v:Visit {{id: toInteger(visits.visit_id),\n",
    "                        room_number: toInteger(visits.room_number),\n",
    "                        admission_type: visits.admission_type,\n",
    "                        admission_date: visits.date_of_admission,\n",
    "                        test_results: visits.test_results,\n",
    "                        status: visits.visit_status\n",
    "    }})\n",
    "        ON CREATE SET v.chief_complaint = visits.chief_complaint\n",
    "        ON MATCH SET v.chief_complaint = visits.chief_complaint\n",
    "        ON CREATE SET v.treatment_description = visits.treatment_description\n",
    "        ON MATCH SET v.treatment_description = visits.treatment_description\n",
    "        ON CREATE SET v.diagnosis = visits.primary_diagnosis\n",
    "        ON MATCH SET v.diagnosis = visits.primary_diagnosis\n",
    "        ON CREATE SET v.discharge_date = visits.discharge_date\n",
    "        ON MATCH SET v.discharge_date = visits.discharge_date\n",
    "        \"\"\"\n",
    "    _ = session.run(query, {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATIENTS = \"https://raw.githubusercontent.com/sakunaharinda/ragatouille/main/data/patients.csv\"\n",
    "\n",
    "with driver.session(database=\"neo4j\") as session:\n",
    "    query = f\"\"\"\n",
    "    LOAD CSV WITH HEADERS\n",
    "    FROM '{PATIENTS}' AS patients\n",
    "    MERGE (p:Patient {{id: toInteger(patients.patient_id),\n",
    "                    name: patients.patient_name,\n",
    "                    sex: patients.patient_sex,\n",
    "                    dob: patients.patient_dob,\n",
    "                    blood_type: patients.patient_blood_type\n",
    "                    }});\n",
    "    \"\"\"\n",
    "    _ = session.run(query, {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "REVIEWS = \"https://raw.githubusercontent.com/sakunaharinda/ragatouille/main/data/reviews.csv\"\n",
    "\n",
    "with driver.session(database=\"neo4j\") as session:\n",
    "        query = f\"\"\"\n",
    "        LOAD CSV WITH HEADERS\n",
    "        FROM '{REVIEWS}' AS reviews\n",
    "        MERGE (r:Review {{id: toInteger(reviews.review_id),\n",
    "                         text: reviews.review,\n",
    "                         patient_name: reviews.patient_name,\n",
    "                         physician_name: reviews.physician_name,\n",
    "                         hospital_name: reviews.hospital_name\n",
    "                        }});\n",
    "        \"\"\"\n",
    "        _ = session.run(query, {})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the nodes are populated, then we create relationships namely `AT`, `HAS`, `COVERED_BY`, `EMPLOYS`, `TREATS`, and `WRITES`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with driver.session(database=\"neo4j\") as session:\n",
    "    query = f\"\"\"\n",
    "    LOAD CSV WITH HEADERS FROM '{VISITS}' AS visits\n",
    "    MATCH (source: `Visit` {{ `id`: toInteger(trim(visits.visit_id)) }})\n",
    "    MATCH (target: `Hospital` {{ `id`: toInteger(trim(visits.hospital_id))}})\n",
    "    MERGE (source)-[r: `AT`]->(target)\n",
    "    \"\"\"\n",
    "    _ = session.run(query, {})\n",
    "    \n",
    "with driver.session(database=\"neo4j\") as session:\n",
    "    query = f\"\"\"\n",
    "    LOAD CSV WITH HEADERS FROM '{VISITS}' AS visits\n",
    "    MATCH (source: `Patient` {{ `id`: toInteger(visits.patient_id) }})\n",
    "    MATCH (target: `Visit` {{ `id`: toInteger(visits.visit_id) }})\n",
    "    MERGE (source)-[: `HAS`]->(target)\n",
    "    \"\"\"\n",
    "    _ = session.run(query, {})\n",
    "    \n",
    "with driver.session(database=\"neo4j\") as session:\n",
    "    query = f\"\"\"\n",
    "    LOAD CSV WITH HEADERS FROM '{VISITS}' AS visits\n",
    "    MATCH (source: `Visit` {{ `id`: toInteger(visits.visit_id) }})\n",
    "    MATCH (target: `Payer` {{ `id`: toInteger(visits.payer_id) }})\n",
    "    MERGE (source)-[covered_by: `COVERED_BY`]->(target)\n",
    "    ON CREATE SET\n",
    "        covered_by.service_date = visits.discharge_date,\n",
    "        covered_by.billing_amount = toFloat(visits.billing_amount) \n",
    "    \"\"\"\n",
    "    _ = session.run(query, {})\n",
    "    \n",
    "with driver.session(database=\"neo4j\") as session:\n",
    "    query = f\"\"\"\n",
    "    LOAD CSV WITH HEADERS FROM '{VISITS}' AS visits\n",
    "    MATCH (source: `Hospital` {{ `id`: toInteger(visits.hospital_id) }})\n",
    "    MATCH (target: `Physician` {{ `id`: toInteger(visits.physician_id) }})\n",
    "    MERGE (source)-[: `EMPLOYS`]->(target)\n",
    "    \"\"\"\n",
    "    _ = session.run(query, {})\n",
    "    \n",
    "with driver.session(database=\"neo4j\") as session:\n",
    "    query = f\"\"\"\n",
    "    LOAD CSV WITH HEADERS FROM '{VISITS}' AS visits\n",
    "    MATCH (source: `Physician` {{ `id`: toInteger(visits.physician_id) }})\n",
    "    MATCH (target: `Visit` {{ `id`: toInteger(visits.visit_id) }})\n",
    "    MERGE (source)-[: `TREATS`]->(target)\n",
    "    \"\"\"\n",
    "    _ = session.run(query, {})\n",
    "    \n",
    "with driver.session(database=\"neo4j\") as session:\n",
    "    query = f\"\"\"\n",
    "    LOAD CSV WITH HEADERS FROM '{REVIEWS}' AS reviews\n",
    "    MATCH (source: `Visit` {{ `id`: toInteger(reviews.visit_id) }})\n",
    "    MATCH (target: `Review` {{ `id`: toInteger(reviews.review_id) }})\n",
    "    MERGE (source)-[: `WRITES`]->(target)\n",
    "    \"\"\"\n",
    "    _ = session.run(query, {})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating our graph, you will be able to see all the nodes and relationships in the AuraDB dashboard. Also, you can execute Cypher queries against your graph and get results. \n",
    "\n",
    "For instance, if you want to know the total number visits in all hospitals in Texas that were paid by the company \"Cigna\" and the total billing amount, you can execute,\n",
    "\n",
    "```cypher\n",
    "MATCH (p:Payer {name: \"Cigna\"})<-[c:COVERED_BY]-(:Visit)-[:AT]->(:Hospital {state_name: \"TX\"}) RETURN COUNT(*) as num_visits, SUM(c.billing_amount) as total_amount;\n",
    "```\n",
    "\n",
    "Your result can be seen as follows in the AuraDB dashboard.\n",
    "\n",
    "| ![arag](resources/auradb.png) | \n",
    "|:--:| \n",
    "| *Cypher query execution against the built graph* |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we are satisfied with the graph, we can then create a `Neo4jVector` index through langchain to embed the user reviews (which is a node in the graph) with properties `review`, `physician_name`, `hospital_name`, `patient_name`. Vector search indices were released as a public beta in Neo4j 5.11. They allow you to run semantic queries directly on your graph. This is really convenient for your chatbot because you can store review embeddings in the same place as your structured hospital system data. Here we have to provide the  `node_label` that we are going to embed, a name to the index, and the `embedding` in addition to the information required for authentication (`username`, `password`, and `url`). Finally, we can create the retriever as we have done many times earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores.neo4j_vector import Neo4jVector\n",
    "\n",
    "neo4j_vector_index = Neo4jVector.from_existing_graph(\n",
    "    embedding=OpenAIEmbeddings(),\n",
    "    username=os.getenv('NEO4J_USERNAME'),\n",
    "    password=os.getenv('NEO4J_PASSWORD'),\n",
    "    url=os.getenv('NEO4J_URI'),\n",
    "    node_label=\"Review\",\n",
    "    index_name=\"review_vector_index\",\n",
    "    text_node_properties=[\n",
    "        \"review\", \"physician_name\", \"hospital_name\", \"patient_name\"\n",
    "    ],\n",
    "    embedding_node_property=\"embedding\"\n",
    ")\n",
    "\n",
    "review_retriever = neo4j_vector_index.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can create our `qa_chain` that answers the user questions based on the given cypher query results or user reviews. Here note that, we do not need to execute any cypher query as we do not need to directly query a particular review, but use the results from the query or reviews collectively to answer a question. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Patients have expressed mixed feelings about hospital efficiency. They appreciated the professionalism of the doctors and the caring nature of the nursing staff but were disappointed by the lack of communication about treatment plans, confusing administrative processes, and constant interruptions during the night. Some also mentioned the lack of vegetarian options in the cafeteria.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What have patients said about hospital efficiency?\"\n",
    "\n",
    "\n",
    "# review_template = \"\"\"\n",
    "# You are an assistant for answering questions based on the user reviews about a hospital.\n",
    "#     Use the following pieces of retrieved context to answer the question. \n",
    "#     Be as detailed as possible. \n",
    "#     If you don't know the answer, just say that you don't know.\n",
    "#     \\nQuestion: {question} \\nContext: {context} \\nAnswer:\"\n",
    "# \"\"\"\n",
    "\n",
    "qa_prompt = hub.pull(\"rlm/rag-prompt\")#\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4\", temperature=0)\n",
    "\n",
    "qa_chain = qa_prompt | llm | StrOutputParser()\n",
    "\n",
    "docs = review_retriever.invoke(question)\n",
    "\n",
    "qa_chain.invoke({\"question\": question, \"context\": docs})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we create the chain that generates a cypher query based on the user question, that can be used to extract information from the graph database. To do that we use langchain's `GraphCypherQAChain`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import GraphCypherQAChain\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "\n",
    "graph = Neo4jGraph(enhanced_schema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can visualize the graph's schema, which acts as the context when translating natural language questions into Cypher queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node properties:\n",
      "- **Hospital**\n",
      "  - `id: INTEGER` Min: 0, Max: 29\n",
      "  - `name: STRING` Example: \"Wallace-Hamilton\"\n",
      "  - `state_name: STRING` Available options: ['CO', 'NC', 'FL', 'GA', 'TX']\n",
      "- **Payer**\n",
      "  - `id: INTEGER` Min: 0, Max: 4\n",
      "  - `name: STRING` Available options: ['Medicaid', 'UnitedHealthcare', 'Aetna', 'Cigna', 'Blue Cross']\n",
      "- **Physician**\n",
      "  - `id: INTEGER` Min: 0, Max: 499\n",
      "  - `name: STRING` Example: \"Joseph Johnson\"\n",
      "  - `school: STRING` Example: \"Johns Hopkins University School of Medicine\"\n",
      "  - `dob: STRING` Example: \"1970-02-22\"\n",
      "  - `grad_year: STRING` Example: \"2000-02-22\"\n",
      "  - `salary: FLOAT` Min: 198347.15752030822, Max: 394259.00931863394\n",
      "- **Patient**\n",
      "  - `id: INTEGER` Min: 0, Max: 9999\n",
      "  - `name: STRING` Example: \"Tiffany Ramirez\"\n",
      "  - `dob: STRING` Example: \"1994-10-06\"\n",
      "  - `blood_type: STRING` Available options: ['O+', 'A-', 'O-', 'AB+', 'A+', 'B-', 'AB-', 'B+']\n",
      "  - `sex: STRING` Available options: ['Female', 'Male']\n",
      "- **Visit**\n",
      "  - `id: INTEGER` Min: 0, Max: 9999\n",
      "  - `admission_date: STRING` Example: \"2022-11-17\"\n",
      "  - `room_number: INTEGER` Min: 101, Max: 500\n",
      "  - `admission_type: STRING` Available options: ['Elective', 'Emergency', 'Urgent']\n",
      "  - `test_results: STRING` Available options: ['Inconclusive', 'Normal', 'Abnormal']\n",
      "  - `status: STRING` Available options: ['DISCHARGED', 'OPEN']\n",
      "  - `discharge_date: STRING` Example: \"2022-12-01\"\n",
      "  - `chief_complaint: STRING` Example: \"Persistent cough and shortness of breath\"\n",
      "  - `treatment_description: STRING` Example: \"Prescribed a combination of inhaled bronchodilator\"\n",
      "  - `diagnosis: STRING` Example: \"J45.909 - Unspecified asthma, uncomplicated\"\n",
      "- **Review**\n",
      "  - `id: INTEGER` Min: 0, Max: 1004\n",
      "  - `physician_name: STRING` Example: \"Laura Brown\"\n",
      "  - `patient_name: STRING` Example: \"Christy Johnson\"\n",
      "  - `text: STRING` Example: \"The medical staff at the hospital were incredibly \"\n",
      "  - `hospital_name: STRING` Example: \"Wallace-Hamilton\"\n",
      "Relationship properties:\n",
      "- **COVERED_BY**\n",
      "  - `service_date: STRING` Example: \"2019-01-13\"\n",
      "  - `billing_amount: FLOAT` Example: \"48391.14147288998\"\n",
      "The relationships:\n",
      "(:Hospital)-[:EMPLOYS]->(:Physician)\n",
      "(:Hospital)-[:COVERED_BY]->(:Physician)\n",
      "(:Physician)-[:TREATS]->(:Visit)\n",
      "(:Patient)-[:HAS]->(:Visit)\n",
      "(:Visit)-[:AT]->(:Hospital)\n",
      "(:Visit)-[:COVERED_BY]->(:Payer)\n",
      "(:Visit)-[:WRITES]->(:Review)\n"
     ]
    }
   ],
   "source": [
    "graph.refresh_schema()\n",
    "print(graph.schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To assist the LLM in generating correct Cypher query we also can provide a few-shot prompt (`cypher_generation_prompt`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cypher_generation_template = \"\"\"\n",
    "    Task:\n",
    "    Generate Cypher query for a Neo4j graph database.\n",
    "\n",
    "    Instructions:\n",
    "    Use only the provided relationship types and properties in the schema.\n",
    "    Do not use any other relationship types or properties that are not provided.\n",
    "\n",
    "    Schema:\n",
    "    {schema}\n",
    "\n",
    "    Note:\n",
    "    Do not include any explanations or apologies in your responses.\n",
    "    Do not respond to any questions that might ask anything other than\n",
    "    for you to construct a Cypher statement. Do not include any text except\n",
    "    the generated Cypher statement. Make sure the direction of the relationship is\n",
    "    correct in your queries. Make sure you alias both entities and relationships\n",
    "    properly. Do not run any queries that would add to or delete from\n",
    "    the database. Make sure to alias all statements that follow as with\n",
    "    statement (e.g. WITH v as visit, c.billing_amount as billing_amount)\n",
    "    If you need to divide numbers, make sure to\n",
    "    filter the denominator to be non zero.\n",
    "\n",
    "    Examples:\n",
    "    # Who is the oldest patient and how old are they?\n",
    "    MATCH (p:Patient)\n",
    "    RETURN p.name AS oldest_patient,\n",
    "        duration.between(date(p.dob), date()).years AS age\n",
    "    ORDER BY age DESC\n",
    "    LIMIT 1\n",
    "\n",
    "    # Which physician has billed the least to Cigna\n",
    "    MATCH (p:Payer)<-[c:COVERED_BY]-(v:Visit)-[t:TREATS]-(phy:Physician)\n",
    "    WHERE p.name = 'Cigna'\n",
    "    RETURN phy.name AS physician_name, SUM(c.billing_amount) AS total_billed\n",
    "    ORDER BY total_billed\n",
    "    LIMIT 1\n",
    "\n",
    "    # Which state had the largest percent increase in Cigna visits\n",
    "    # from 2022 to 2023?\n",
    "    MATCH (h:Hospital)<-[:AT]-(v:Visit)-[:COVERED_BY]->(p:Payer)\n",
    "    WHERE p.name = 'Cigna' AND v.admission_date >= '2022-01-01' AND\n",
    "    v.admission_date < '2024-01-01'\n",
    "    WITH h.state_name AS state, COUNT(v) AS visit_count,\n",
    "        SUM(CASE WHEN v.admission_date >= '2022-01-01' AND\n",
    "        v.admission_date < '2023-01-01' THEN 1 ELSE 0 END) AS count_2022,\n",
    "        SUM(CASE WHEN v.admission_date >= '2023-01-01' AND\n",
    "        v.admission_date < '2024-01-01' THEN 1 ELSE 0 END) AS count_2023\n",
    "    WITH state, visit_count, count_2022, count_2023,\n",
    "        (toFloat(count_2023) - toFloat(count_2022)) / toFloat(count_2022) * 100\n",
    "        AS percent_increase\n",
    "    RETURN state, percent_increase\n",
    "    ORDER BY percent_increase DESC\n",
    "    LIMIT 1\n",
    "\n",
    "    # How many non-emergency patients in North Carolina have written reviews?\n",
    "    MATCH (r:Review)<-[:WRITES]-(v:Visit)-[:AT]->(h:Hospital)\n",
    "    WHERE h.state_name = 'NC' and v.admission_type <> 'Emergency'\n",
    "    RETURN count(*)\n",
    "\n",
    "    String category values:\n",
    "    Test results are one of: 'Inconclusive', 'Normal', 'Abnormal'\n",
    "    Visit statuses are one of: 'OPEN', 'DISCHARGED'\n",
    "    Admission Types are one of: 'Elective', 'Emergency', 'Urgent'\n",
    "    Payer names are one of: 'Cigna', 'Blue Cross', 'UnitedHealthcare', 'Medicare',\n",
    "    'Aetna'\n",
    "\n",
    "    A visit is considered open if its status is 'OPEN' and the discharge date is\n",
    "    missing.\n",
    "    Use abbreviations when\n",
    "    filtering on hospital states (e.g. \"Texas\" is \"TX\",\n",
    "    \"Colorado\" is \"CO\", \"North Carolina\" is \"NC\",\n",
    "    \"Florida\" is \"FL\", \"Georgia\" is \"GA\", etc.)\n",
    "\n",
    "    Make sure to use IS NULL or IS NOT NULL when analyzing missing properties.\n",
    "    Never return embedding properties in your queries. You must never include the\n",
    "    statement \"GROUP BY\" in your query. Make sure to alias all statements that\n",
    "    follow as with statement (e.g. WITH v as visit, c.billing_amount as\n",
    "    billing_amount)\n",
    "    If you need to divide numbers, make sure to filter the denominator to be non\n",
    "    zero.\n",
    "\n",
    "    The question is:\n",
    "    {question}\n",
    "\"\"\"\n",
    "\n",
    "cypher_generation_prompt = PromptTemplate(\n",
    "    input_variables=[\"schema\", \"question\"], template=cypher_generation_template\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After defining the cypher generation prompt we create a `graph_query_chain` that translates the user question into a Cypher query, executes it against the database, and returns the answer. You can set the `verbose` as `True` if it is required to see the intermediate steps like the generated query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The physicians who treated patients with O- blood type are Jeffrey Williams, Leslie Williams, Luis Powell MD, Taylor Williams PhD, Nancy Nichols, Kyle Campbell, Abigail Cummings, Nathan Smith, Daniel Morgan II, and Charles Kim.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "graph_query_chain = GraphCypherQAChain.from_llm(\n",
    "    llm, \n",
    "    graph=graph, \n",
    "    validate_cypher=True,\n",
    "    cypher_prompt=cypher_generation_prompt,\n",
    "    verbose=False,\n",
    "    return_intermediate_steps=True\n",
    "    \n",
    ")\n",
    "\n",
    "question = \"Who are the physicians who treated patients having O- blood type?\"\n",
    "\n",
    "result = graph_query_chain.invoke({'query': question})\n",
    "intermediate_results = result['intermediate_steps']\n",
    "\n",
    "qa_chain.invoke({\"question\": question, \"context\": intermediate_results})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chain to answer when fallback happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "fallback_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    You are an assistant for question-answering tasks. Answer the question based on your knowledge. Use three sentences maximum and keep the answer concise.\\n\\n\n",
    "    Question: {question}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "fallback_chain = fallback_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A query router that performs query analysis and redirects the user's question either to the Neo4J vector index, the Neo4J graph database, or to the fallback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How is the patient safety in the hospital?: datasource='vectorstore'\n",
      "What are the specialities of all the doctors in all the hospitals?: datasource='graph'\n",
      "What is the capital of France?: datasource='fallback'\n"
     ]
    }
   ],
   "source": [
    "class QueryRouter(BaseModel):\n",
    "    \n",
    "    \"\"\"Routes the question to either the vectorstore or the graph database\"\"\"\n",
    "    \n",
    "    datasource: Literal['vectorstore', 'graph', 'fallback'] = Field(...,description=\"The datasource to use for answering the user question. If the user question can be answered using the reviews about the hospital, the datasource should be set to 'vectorstore'. If the question should be answered using the information from a databse containing information about hospitals that a company manages, the datasource should be set to 'graph'. If the question can be answered using LLM's internal knowledge, the datasource should be set to 'fallback'\")\n",
    "    \n",
    "\n",
    "question = \"How is the patient safety in the hospital?\"\n",
    "\n",
    "query_llm = llm.with_structured_output(QueryRouter)\n",
    "\n",
    "query_router_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"You are an expert at routing a user question to a vectorstore or to a graph database containing information from a hospital system. The vectorstore contains documents related to the user reviews of a hospital.\n",
    "Use the vectorstore for questions that can be answered using peoples' opinions on the hospital. Otherwise, use graphs to answer questions using the graph database containing information from a company database that manages several hospitals. If the question can be answered using LLM's internal knowledge, use fallback.\\n\\n\n",
    "Question: {question}\"\"\"\n",
    ")\n",
    "\n",
    "query_routing_chain = (query_router_prompt | query_llm)\n",
    "\n",
    "print(f\"{question}: {query_routing_chain.invoke({'question': question})}\")\n",
    "system_q = \"What are the specialities of all the doctors in all the hospitals?\"\n",
    "print(f\"{system_q}: {query_routing_chain.invoke({'question': system_q})}\")\n",
    "fallback_q = \"What is the capital of France?\"\n",
    "print(f\"{fallback_q}: {query_routing_chain.invoke({'question': fallback_q})}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hallucination evaluator checks whether or not the generated answer is grounded by the facts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HallucinationEvaluator(BaseModel):\n",
    "    \"\"\"Binary score for hallucination present in generation answer.\"\"\"\n",
    "\n",
    "    grade: str = Field(...,\n",
    "        description=\"Answer is grounded in the facts, 'yes' or 'no'\"\n",
    "    )\n",
    "    \n",
    "hallucination_llm = llm.with_structured_output(HallucinationEvaluator)\n",
    "hallucination_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    You are a grader assessing whether an LLM generation is grounded in / supported by a set of retrieved facts. \\n\n",
    "    Give a binary score 'yes' or 'no'. 'Yes' means that the answer is grounded in / supported by the set of facts.\\n\\n\n",
    "    Set of facts: {documents} \\n\\n LLM generation: {generation}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "hallucination_chain = hallucination_prompt | hallucination_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HallucinationEvaluator(grade='no')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generation = qa_chain.invoke({\"question\": question, \"context\": docs})\n",
    "n_question = \"What are the specialities of all the doctors in all the hospitals?\"\n",
    "n_docs = review_retriever.invoke(n_question)\n",
    "\n",
    "hallucination_chain.invoke({\"documents\": n_docs, \"generation\": generation})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph state definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from typing import List\n",
    "\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph.\n",
    "\n",
    "    Attributes:\n",
    "        question: question\n",
    "        generation: LLM generation\n",
    "        documents: list of documents\n",
    "    \"\"\"\n",
    "\n",
    "    question: str\n",
    "    generation: str\n",
    "    documents: List[str]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating methods for the nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(state: GraphState):\n",
    "    \"\"\"\n",
    "    Retrieves the documents from the vectorstore.\n",
    "    \n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, documents, that contains retrieved documents\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"> ðŸ“ƒ Retrieving user reviews ...\")\n",
    "    \n",
    "    question = state[\"question\"]\n",
    "    docs = review_retriever.invoke(question)\n",
    "    \n",
    "    state[\"documents\"] = docs\n",
    "    \n",
    "    return state\n",
    "\n",
    "def fallback(state):\n",
    "    \"\"\"\n",
    "    Fallback to LLM's internal knowledge.\n",
    "    \n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, generation, that contains LLM generation\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"> ðŸ‘ˆ Fallback to LLM's internal knowledge ...\")\n",
    "    \n",
    "    question = state[\"question\"]\n",
    "    generation = fallback_chain.invoke({\"question\": question})\n",
    "    \n",
    "    state[\"generation\"] = generation\n",
    "    \n",
    "    return state\n",
    "\n",
    "def query_graph(state):\n",
    "    \"\"\"\n",
    "    Queries the graph database.\n",
    "    \n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, generation, that contains LLM generation\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"> ðŸ“Š Querying the graph database ...\")\n",
    "    \n",
    "    question = state[\"question\"]\n",
    "    generation = graph_query_chain.invoke({\"query\": question})\n",
    "    \n",
    "    state[\"documents\"] = generation['intermediate_steps']\n",
    "    \n",
    "    return state\n",
    "\n",
    "def generate(state):\n",
    "    \"\"\"\n",
    "    Generates an answer using the retrieved documents/query results.\n",
    "    \n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, generation, that contains LLM generation\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"> ðŸ§  Generating an answer ...\")\n",
    "    \n",
    "    question = state[\"question\"]\n",
    "    docs = state[\"documents\"]\n",
    "    generation = qa_chain.invoke({\"question\": question, \"context\": docs})\n",
    "    \n",
    "    state[\"generation\"] = generation\n",
    "    \n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating conditional edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_question(state):\n",
    "    \"\"\"\n",
    "    Route question to web search or RAG.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Next node to call\n",
    "    \"\"\"\n",
    "    \n",
    "    question = state[\"question\"]\n",
    "    route = query_routing_chain.invoke({\"question\": question})\n",
    "    \n",
    "    if route.datasource == \"vectorstore\":\n",
    "        print(\"> ðŸ“š Routing to the review database ...\")\n",
    "        return \"retrieve\"\n",
    "    \n",
    "    elif route.datasource == \"graph\":\n",
    "        print(\"> ðŸ“Š Routing to the graph database ...\")\n",
    "        return \"query_graph\"\n",
    "    \n",
    "    else:\n",
    "        print(\"> ðŸ‘ˆ Routing to fallback...\")\n",
    "        return \"fallback\"\n",
    "    \n",
    "    \n",
    "def check_hallucination(state):\n",
    "    \"\"\"\n",
    "    Check if the generation is hallucinated.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Next node to call\n",
    "    \"\"\"\n",
    "    \n",
    "    generation = state[\"generation\"]\n",
    "    docs = state[\"documents\"]\n",
    "    \n",
    "    grounded = hallucination_chain.invoke({\"documents\": docs, \"generation\": generation})\n",
    "    \n",
    "    if grounded.grade == \"yes\":\n",
    "        print(\"> âœ… \\033[92mAnswer addresses the question\\033[0m\")\n",
    "        return \"useful\"\n",
    "    \n",
    "    else:\n",
    "        print(\"> âŒ \\033[91mGeneration is not grounded in the documents\\033[0m\")\n",
    "        return \"not supported\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the graph with defined nodes and edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "workflow.add_node(\"retrieve\", retrieve)\n",
    "workflow.add_node(\"query_graph\", query_graph)\n",
    "workflow.add_node(\"fallback\", fallback)\n",
    "workflow.add_node(\"generate\", generate)\n",
    "\n",
    "workflow.set_conditional_entry_point(\n",
    "    route_question,\n",
    "    {\n",
    "        \"retrieve\": \"retrieve\",\n",
    "        \"query_graph\": \"query_graph\",\n",
    "        \"fallback\": \"fallback\"\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.add_edge('query_graph', 'generate')\n",
    "workflow.add_edge('retrieve', 'generate')\n",
    "workflow.add_conditional_edges(\n",
    "    'generate',\n",
    "    check_hallucination,\n",
    "    {\n",
    "        \"useful\": END,\n",
    "        \"not supported\": \"generate\"\n",
    "    }\n",
    ")\n",
    "workflow.add_edge('fallback', END)\n",
    "\n",
    "app = workflow.compile()\n",
    "\n",
    "def run_pipeline(question):\n",
    "    inputs = {\"question\": question}\n",
    "    for output in app.stream(inputs):\n",
    "        for key, value in output.items():\n",
    "            if key == 'generate' or key == 'fallback':\n",
    "                print()\n",
    "                print(f'Question: {inputs[\"question\"]}')\n",
    "                print(f\"Answer: {value['generation']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> ðŸ“š Routing to the review database ...\n",
      "> ðŸ“ƒ Retrieving user reviews ...\n",
      "> ðŸ§  Generating an answer ...\n",
      "> âœ… \u001b[92mAnswer addresses the question\u001b[0m\n",
      "\n",
      "Question: What have patients said about hospital efficiency?\n",
      "Answer: Patients have expressed mixed feelings about hospital efficiency. Some appreciated the professionalism and skills of the doctors and the caring nature of the nursing staff. However, they were disappointed with the lack of vegetarian options in the cafeteria, lack of communication about treatment plans, constant interruptions during the night, and confusing administrative processes.\n"
     ]
    }
   ],
   "source": [
    "run_pipeline(\"What have patients said about hospital efficiency?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tha Langsmith trace for the above workflow will look like [this](https://smith.langchain.com/public/cb562c97-44e4-407b-9bf1-b8c2f35e3e1b/r)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> ðŸ“Š Routing to the graph database ...\n",
      "> ðŸ“Š Querying the graph database ...\n",
      "> ðŸ§  Generating an answer ...\n",
      "> âœ… \u001b[92mAnswer addresses the question\u001b[0m\n",
      "\n",
      "Question: What is the total number of visits in all hospitals in Texas that were paid by the company 'Cigna'?\n",
      "Answer: The total number of visits in all hospitals in Texas that were paid by the company 'Cigna' is 204.\n"
     ]
    }
   ],
   "source": [
    "# run_pipeline(\"Who are the physicians who treated patients that have O- blood type and who is the most frequent payer for them?\")\n",
    "run_pipeline(\"What is total number visits in all hospitals in Texas that were paid by the company 'Cigna'?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Langsmith trace for the above workflow will look like [this](https://smith.langchain.com/public/bb4c63f0-3434-43b7-a934-f0542a155e69/r)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> ðŸ‘ˆ Routing to fallback...\n",
      "> ðŸ‘ˆ Fallback to LLM's internal knowledge ...\n",
      "\n",
      "Question: Hi! How are you doing today?\n",
      "Answer: As an artificial intelligence, I don't have feelings, but I'm here and ready to assist you. How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "run_pipeline(\"Hi! How are you doing today?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Langsmith trace for the above workflow will look like [this](https://smith.langchain.com/public/85d98d3e-9e01-45da-a1f7-e99dd3cbd0b6/r)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
